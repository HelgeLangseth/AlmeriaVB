{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational message passing\n",
    "This is an extremely crude implementation of the Variational Message passing example in the original paper by \n",
    "Winn & Bishop.\n",
    "\n",
    "Model description: We have a precision a priori Gamma distributed, and a mean a priori following a Gaussian.\n",
    "\n",
    "We then have a dataset sampled from Normal(5, 1). The key is to find posterior mean and precision.\n",
    "This is done using VMP. Everything here is defined tailor-made for the current model. Hence, no clever scoping of\n",
    "messages or whatever goes on; we simply hard-code the structure and the sequencing, and get the expected result.\n",
    "\n",
    "There is no ELBO calculation here, and also no convergence monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import special, stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Exponential Family superclass\n",
    "Many of the operations in VMP are shared among ExpFam distributions. We therefore define a superclass taht takes of that, and make subclasses for each of the actual distributions afterwards.\n",
    "\n",
    "The methods we need are as follows:\n",
    "* **Initialization** (done by the `__init__`-method). The code here assumes that the **priors** are supplied at initialization time. Furthermore, the method sets aside space for an observation (may be None) and messages.\n",
    "* **Translation** between _natural parameters_ and _moment parameters_. As we have seen previously, the way to do the translation depends on the distribution, hence these methods (`translate_to_moment_parameters` and `translate_to_natural_parameters` are virtual in the superclass).\n",
    "* Accepting **incoming messages**. This amounts to taking care of what comes from whom, and is straightforward using the `dict`-datastructure. It is the same for all distributions, and will not be refined in the subclasses.\n",
    "* Sending **outgoing messages**. We need to know how to send messages to both parents and children. What is sent depends on the distribution of the sender and the receover, hence is overwritten in the subclasses.\n",
    "\n",
    "This class is finished, no need to fiddle with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialFamilyDistribution:\n",
    "    def __init__(self, moment_parameters=None, natural_parameters=None, observation=None):\n",
    "        if moment_parameters is not None:\n",
    "            self.moment_parameters = np.array(moment_parameters)\n",
    "            self.translate_to_natural_parameters()\n",
    "        else:\n",
    "            self.natural_parameters = np.array(natural_parameters)\n",
    "            self.translate_to_moment_parameters()\n",
    "\n",
    "        # Keep the prior.\n",
    "        self.prior = self.natural_parameters\n",
    "\n",
    "        # Enable a storage point for all messages. These are stored in a dictionary\n",
    "        self.messages = {}\n",
    "\n",
    "        # If we have an observation, then store that, too\n",
    "        self.observation = observation\n",
    "\n",
    "    def translate_to_moment_parameters(self):\n",
    "        # This depends on the distribution type, so will be defined in subclasses\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def translate_to_natural_parameters(self):\n",
    "        # This depends on the distribution type, so will be defined in subclasses\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def accept_incoming_messages(self, message, sender):\n",
    "        self.messages[sender] = message\n",
    "\n",
    "    def update_based_on_incoming_messages(self):\n",
    "        # Add msg to the natural parameters\n",
    "        self.natural_parameters = self.prior\n",
    "        for sender in self.messages.keys():\n",
    "            message = self.messages[sender]\n",
    "            assert np.all(np.shape(message) == np.shape(self.natural_parameters))\n",
    "            self.natural_parameters += np.array(message)\n",
    "\n",
    "        # Update moment parameters -- just to have them for plotting and whatnot\n",
    "        self.translate_to_moment_parameters()\n",
    "\n",
    "        # The messages we have received are all incorporated, and will be voided.\n",
    "        self.messages = {}\n",
    "\n",
    "    def generate_message_to_child(self):\n",
    "        # Messages are calculated as the expectation of the sufficient statistics.\n",
    "        # It is depending on the distribution, hence defined at subclass level\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def generate_message_to_parent(self, receiver):\n",
    "        # Messages are calculated based on the recipient. It sends thee expected\n",
    "        # natural parameters in the conjugate representation.\n",
    "        # Quite \"nasty\" stuff, and written at subclass level\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Gaussian class\n",
    "We implement the Gaussian distribution as a subclass of the general ExponentialFamily. \n",
    "Some stuff is directly inherited from the superclass (namely initialization, accepting messages, and updating natural parameters based on the selected messages).\n",
    "\n",
    "**These things are to be implemented:**\n",
    "* Translation **from moment parameters to natural parameters** (`translate_to_moment_parameters`). This has already beenm implemented in the previous code task. Note that we only care about natural parameters here, not the log partition function. \n",
    "* Translation **from natural parameters to moment parameters** (`translate_to_natural_parameters`). This is the \"inverse\" of `translate_to_moment_parameters`.\n",
    "* Generate **messages to children:** In this model, the only message from a Gaussian to a child is from the laten/unobserved variable representing the unknown mean and down to the data-points, that are also Gaussian.\n",
    "* Generate **message to parents**: The observed variables will send a message to the mean as well as to the precision variable. That means, we must be able to send to both Gaussian and Gamma parents. Messages are described in the slides, and should be in `generate_message_to_parent`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian(ExponentialFamilyDistribution):\n",
    "    def __init__(self, moment_parameters=None, natural_parameters=None, observation=None):\n",
    "        # Initialization is simply handed off to superclass\n",
    "        super(Gaussian, self).__init__(moment_parameters=moment_parameters,\n",
    "                                       natural_parameters=natural_parameters,\n",
    "                                       observation=observation)\n",
    "\n",
    "    def translate_to_moment_parameters(self):\n",
    "        # Rule is: Natural params == (mu*q, -.5q), where q = 1/variance\n",
    "        # Want to return [mu, sigma_square]\n",
    "        assert self.natural_parameters is not None\n",
    "        \n",
    "        self.moment_parameters = [????, ????]\n",
    "        return self.moment_parameters\n",
    "\n",
    "    def translate_to_natural_parameters(self):\n",
    "        # Rule is: Natural params == (mu*q, -.5q), where q = 1/variance\n",
    "        # Want to return [eta1, eta2]\n",
    "        assert self.moment_parameters is not None\n",
    "\n",
    "        self.natural_parameters = [????, ????]\n",
    "        return self.natural_parameters\n",
    "\n",
    "    def generate_message_to_child(self):\n",
    "        # In our model a Gaussian sends a message to a child only in one case:\n",
    "        # The variable mu sends to its children X_i. X_i are Gaussians.\n",
    "        # The Gaussian will send a message giving\n",
    "        # E[X], E[X**2]\n",
    "        # where the expectation is to be taken over its own distribution.\n",
    "        # Using moment params this is simple:\n",
    "        #     E[X] = self.moment_parameters[0]\n",
    "        #     E[X**2] = self.moment_parameters[0]**2 + self.moment_parameters[1]\n",
    "        \n",
    "        return = [????, ????]\n",
    "\n",
    "    def generate_message_to_parent(self, receiver):\n",
    "        # The receiver can be either a Gaussian (X_i sends to mu) or a Gamma (X_i sends to tau).\n",
    "        # The shape of the message depends on the receiver, so we need to make sure we do this accordingly.\n",
    "        if isinstance(receiver, Gaussian):\n",
    "            # Message to a Gaussian is the local model's\n",
    "            # best guess on the natural parameters,\n",
    "            # [ E[Q]  * data_value,  -.5 * E(Q)]\n",
    "            # These are the expected natural parameters\n",
    "            # For this to work, the node must have already received the message from parents determining Q.\n",
    "            # We therefore check for incoming messages being filled, where the sender is Gamma distributed.\n",
    "            incoming_from_gamma = None\n",
    "            for sender in self.messages.keys():\n",
    "                # Go through all messages the variable has received\n",
    "                if isinstance(sender, Gamma):\n",
    "                    # We have something from a Gamma. Since the model is known to have only\n",
    "                    # Gamma parent, this is the one we look for\n",
    "                    incoming_from_gamma = self.messages[sender]\n",
    "                    break\n",
    "            # Check we have something there\n",
    "            assert incoming_from_gamma is not None\n",
    "\n",
    "            # The value of incoming is a message from my Gamma-distributed parent.\n",
    "            # It has the information [E[log(tau)], E[tau]], and the E[tau] part plays the role of Q here\n",
    "            # Next, the observation (X_i is observed) will play the role as E[mean].\n",
    "            message = [????, ????]\n",
    "\n",
    "        elif isinstance(receiver, Gamma):\n",
    "            # Message to a Gamma is the local model's\n",
    "            # best guess on the natural parameters,\n",
    "            # [.5,  -.5(x_i^2 - 2* x_i * E[mu] + E[mu^2])]\n",
    "            # These are the expected natural parameters\n",
    "\n",
    "            # For this to work, I must have already received the message from my parent determining mu.\n",
    "            # So, check if we have indeed received an incoming message from a Gaussian.\n",
    "            # In a general setup we may have more than two parents, and then this simple check would not work.\n",
    "            # Rather, we should go through all parents and children, check for all but one message being received,\n",
    "            # and then the variable with a missing message would be the one we could send to.\n",
    "            incoming_from_gauss = None\n",
    "            for sender in self.messages.keys():\n",
    "                if isinstance(sender, Gaussian):\n",
    "                    incoming_from_gauss = self.messages[sender]\n",
    "            assert incoming_from_gauss is not None\n",
    "\n",
    "            # Now, incoming is a message from my Gaussian-distributed parent.\n",
    "            # It has the information [E[mu], E[mu**2]]\n",
    "            # The message to send to the Gamma is [1/2, -1/2 E[ (x_i - mu)**2 ]\n",
    "            message = [????, ????]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Not a conjugate family member this code supports.\")\n",
    "\n",
    "        return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Gamma class\n",
    "Much like the Gauss-class, we here need to implement the distribution-specific operations. We make a simplification based on the model structure: There is no Gamma-distributed variable in the model that has a parent, hence we need n ot consider an implemebntation of `generate_message_to_parent`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gamma(ExponentialFamilyDistribution):\n",
    "    def __init__(self, moment_parameters=None, natural_parameters=None, observation=None):\n",
    "        super(Gamma, self).__init__(moment_parameters=moment_parameters,\n",
    "                                    natural_parameters=natural_parameters,\n",
    "                                    observation=observation)\n",
    "\n",
    "    def translate_to_moment_parameters(self):\n",
    "        # Rule is: Natural params == [alpha - 1, -beta]\n",
    "        # Want to return [alpha, beta]\n",
    "        assert self.natural_parameters is not None\n",
    "\n",
    "        \n",
    "        self.moment_parameters = [????, ????]\n",
    "        return self.moment_parameters\n",
    "\n",
    "    def translate_to_natural_parameters(self):\n",
    "        # Rule is: Natural params == [alpha - 1, -beta]\n",
    "        # Want to return [eta1, eta2]\n",
    "        assert self.moment_parameters is not None\n",
    "        \n",
    "        \n",
    "        self.natural_parameters = [????, ????]\n",
    "        return self.natural_parameters\n",
    "\n",
    "    def generate_message_to_child(self):\n",
    "        # The Gamma will send a message to Gaussian variables giving\n",
    "        # E[log(X)], E[X]]\n",
    "        # where the expectation is to be taken over its own distribution.\n",
    "        # Using moment params this is simple:\n",
    "        #     E[log(X)] = - log(self.beta) + digamma(alpha)\n",
    "        #     E[X] = alpha / beta\n",
    "\n",
    "        return = [????, ????]\n",
    "\n",
    "    def generate_message_to_parent(self, receiver):\n",
    "        # No parent for the Gamma in this model, so we do not have to implement it\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VariationalMessagePassingExample class\n",
    "Simply implements the example: During initializatoin it generates the required variables, then a training procedure that hardcodes the model structure (that is, which variable sends messages to which recepients before a variable can be updated), and finally a plotting method that shows the posterior over the (mean, precision)-space. \n",
    "\n",
    "This class is finished, no need to fiddle with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalMessagePassingExample:\n",
    "\n",
    "    def __init__(self, data_set):\n",
    "\n",
    "        # data_set is a vector of observations -- length = N\n",
    "        self.data_set = data_set\n",
    "        self.N = len(self.data_set)\n",
    "\n",
    "        # tau: Scalar value for precision.\n",
    "        # A priori Gamma distributed with \"uninormatve\" parameters:\n",
    "        self.tau = Gamma(moment_parameters=[1e-3, 1E-3])\n",
    "\n",
    "        # mu: Scalar value for the mean.\n",
    "        # A priori Normal distributed with gigh variance:\n",
    "        self.mu = Gaussian(moment_parameters=[0, 1E6])\n",
    "\n",
    "        # observations: These are the x_i variables.\n",
    "        # The prior distribution p(x_i|mu, tau) is a\n",
    "        # Gaussian with mean mu and precision tau, but since the\n",
    "        # variables are all observed we do not really have to relate to this\n",
    "        # during \"start-up\". Rather, we will initialize with some numerical values just to get going.\n",
    "        self.observations = []\n",
    "        for idx in range(self.N):\n",
    "            self.observations.append(Gaussian(moment_parameters=[0, 1],\n",
    "                                              observation=self.data_set[idx]))\n",
    "\n",
    "    def train(self, no_iter=10, plot_all=False):\n",
    "\n",
    "        # Here we strongly utilize the structure of the domain.\n",
    "        # If we do the following passing scheme, everything will work just fine:\n",
    "        # 1) tau sends to all observations.\n",
    "        # 2) observations x_i send to mu.\n",
    "        # 3) mu needs updating, as it has received all its messages\n",
    "        # 4) mu sends to all observations\n",
    "        # 5) observations x_i send to tau.\n",
    "        # 6) tau can update itself\n",
    "        # At this point we have done one cycle.\n",
    "        # mu and tau are updated, while x_i (observed) does not need to do anything.\n",
    "        # If we want to do another cycle, we just go back to step 1) again, and send\n",
    "        # a new message, based on the updated information at tau, to the observations.\n",
    "\n",
    "        for i in range(no_iter):\n",
    "\n",
    "            # Message from tau to all the observations:\n",
    "            msg = self.tau.generate_message_to_child()\n",
    "            for obs in self.observations:\n",
    "                obs.accept_incoming_messages(msg, self.tau)\n",
    "\n",
    "            # Message from the observations to mu:\n",
    "            for obs in self.observations:\n",
    "                msg = obs.generate_message_to_parent(receiver=self.mu)\n",
    "                self.mu.accept_incoming_messages(msg, obs)\n",
    "\n",
    "            # Update mu\n",
    "            self.mu.update_based_on_incoming_messages()\n",
    "\n",
    "            # Message from mu to all the data-nodes:\n",
    "            msg = self.mu.generate_message_to_child()\n",
    "            for obs in self.observations:\n",
    "                obs.accept_incoming_messages(msg, self.mu)\n",
    "\n",
    "            # Message from the data-nodes to tau:\n",
    "            for obs in self.observations:\n",
    "                msg = obs.generate_message_to_parent(receiver=self.tau)\n",
    "                self.tau.accept_incoming_messages(msg, obs)\n",
    "\n",
    "            # Update tau\n",
    "            self.tau.update_based_on_incoming_messages()\n",
    "\n",
    "            print(\"\\n\\nUpdated {:d} time(s):\".format(i + 1))\n",
    "            print(\"Posterior mean is Normal({:.2f}, {:.2f})\".format(\n",
    "                self.mu.moment_parameters[0], self.mu.moment_parameters[1]))\n",
    "            print(\"Posterior precision is Gamma({:.2f}, {:.2f}), with mean {:.2f}\".format(\n",
    "                self.tau.moment_parameters[0], self.tau.moment_parameters[1],\n",
    "                self.tau.moment_parameters[0] / self.tau.moment_parameters[1]))\n",
    "\n",
    "            if plot_all or i == no_iter - 1:\n",
    "                self.plot_curve(iteration=i)\n",
    "                \n",
    "    def plot_curve(self, iteration):\n",
    "        # This method plots the posterior over the parameter space (mu, tau)\n",
    "        mu_range = np.linspace(3, 7, 500).astype(np.float32)\n",
    "        precision_range = np.linspace(1E-10, 2, 500).astype(np.float32)\n",
    "        mu_mesh, precision_mesh = np.meshgrid(mu_range, precision_range)\n",
    "        variational_log_pdf = \\\n",
    "            stats.norm.logpdf(mu_mesh,\n",
    "                              loc=self.mu.moment_parameters[0],\n",
    "                              scale=self.mu.moment_parameters[1]) + \\\n",
    "            stats.gamma.logpdf(x=precision_mesh,\n",
    "                               a=self.tau.moment_parameters[0],\n",
    "                               scale=1. / self.tau.moment_parameters[1])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.contour(mu_mesh, precision_mesh, variational_log_pdf, 25)\n",
    "        plt.title('Iteration {:d}'.format(iteration + 1))\n",
    "        plt.show()\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, this is some code to test everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    np.random.seed(123)\n",
    "    dataset = 5 + np.random.randn(4)\n",
    "    example = VariationalMessagePassingExample(dataset)\n",
    "    example.train(no_iter=5, plot_all=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
